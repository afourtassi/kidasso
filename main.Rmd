---
title: "conceptNet"
date: "2/15/2018"
output: html_document
---

Libraries
```{r setup, include=FALSE}
 library(purrr)
  library(readr)
  library(ggplot2)
  library(langcog)
  library(boot)
  library(dplyr)
  library(tidyr)
  library(wordbankr)
  library(directlabels)
  library(stringr)
  library(lmtest)
  library(rwebppl)
  library(jsonlite)
  library(nlme)
  library(feather)
  library(broom)
  library(HDInterval)
  library(BBmisc)
  library(wordVectors)
  library(magrittr)
```

Data

```{r}

d <- read_delim("data/associations.txt", delim = "\t") 
  
```

This function is used to recode symbols in cmu phonetic dictionary in with a unique character (easier to compute Edit distance) 
```{r}

#Read in phones and the corresponding set of characters

characters <- read_delim("data/symbolsToChar.txt", delim = "\t", col_names = FALSE) 
phones <- read_delim("data/cmu_symbols.txt", delim = "\t", col_names = FALSE)
phon_dict <- bind_cols(phones, characters)

#Converts string to its representation using the symbols
convert <- function(str, combined) {
    if (typeof(str) != "character" && class(str) != "factor") 
        stop(sprintf("Illegal data type: %s", typeof(str)))
    if (class(str) == "factor") 
        str = as.character(str)
    if (length(str) == 0)
        return(integer(0))
    splitstring = strsplit(str, split=" ")
    result_string = ""
    for (i in splitstring) {
      for (j in i) {
        filtered <- filter(combined, X1 == j)
        converted <- select(filtered, X11)
        result_string <- paste(result_string, converted)
      }
    }
    return(result_string)
}

```

Here the main analyses

```{r}
#For each word, list all other the words that have been mentioned 

#I should calculate the most frequent response and the percentage from 

dict <- read_delim("data/cmu_dict.txt", delim = ",") 

d_assoc <- d %>%
  dplyr::group_by(Experimenter_Word, Age2, Child_Word) %>%
  dplyr::summarise(n=n()) %>%
  dplyr::mutate(percent = 100*n/sum(n)) %>%
  dplyr::filter(percent == max(percent)) 

Exp_words <- d_assoc %>%
  ungroup() %>%
  select(Experimenter_Word) %>%
  distinct() %>%
  mutate(Word = toupper(Experimenter_Word)) %>%
  left_join(dict) %>%
  select(-Word) %>%
  rename(Experimenter_Word_phon = Phonetic)

Chi_words <- d_assoc %>%
  ungroup() %>%
  select(Child_Word) %>%
  distinct() %>%
  mutate(Word = toupper(Child_Word)) %>%
  left_join(dict) %>%
  select(-Word) %>%
  rename(Child_Word_phon = Phonetic)
  
d_assoc_phon <- d_assoc %>%
  left_join(Exp_words) %>%
  left_join(Chi_words) %>%
  rowwise() %>%
  mutate(
    Exp_code = convert(Experimenter_Word_phon, phon_dict), 
    Child_code = convert(Child_Word_phon, phon_dict)
    ) %>%
  mutate(Phon_dist = adist(Exp_code, Child_code))


```

Here we reproduce the development of paradigmatic vs. syntagmatic as in Erica's previous research

```{r}
d_age <- d %>%
  group_by(Age2) %>%
  summarise(mean = mean(Para),
            sd = sd(Para),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se)
  
#d_age$Age2 = factor(d_age$Age2, levels = c("Younger", "Older", "Adult"))`

ggplot(d_age, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 

```

Here the development in terms of reliance on phonetic distance 

I should filter the words for both adults and children
```{r}

word_excl <- (d_assoc_phon %>%
  filter(is.na(Child_Word_phon) | Phon_dist =="0") %>%
  distinct(Experimenter_Word))$Experimenter_Word

phon_plot <- d_assoc_phon %>%
  filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age2) %>%
  summarise(mean = mean(Phon_dist),
            sd = sd(Phon_dist),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) #%>%
  #select(-sd, -n0, -se)

phon_plot$Age2 = factor(phon_plot$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(phon_plot, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 

##Things to do probably:

# 1) Why is the adult similarity almost as low as the younger children? For example, we can  select the words that have the lowest edit distance (say, d<4) in both Younger and adults and see if they are similar? 

# 2) Also probably break things out by lexical category, e.g., content wrods (nouns, verbs, adjectivees) vs. function words (preposition, ...)


```

Now work with semantic similarity from CHILDES 

```{r}

#Generate the model and store it in "derived"
model = train_word2vec("data/corpus.txt",
                             output="corpus.bin", threads = 4,
                             vectors = 100, window=20, cbow=1, min_count = 10, force= TRUE)

#Read the model 
model = read.vectors("derived/corpus.bin")
```

```{r}

Child_words <- (d %>%
  distinct(Child_Word))$Child_Word

Experimenter_words <- (d %>%
  distinct(Experimenter_Word))$Experimenter_Word

model_cue <- model[[which(rownames(model) %in% Experimenter_words), average=FALSE]]

model_target <- model[[which(rownames(model) %in% Child_words), average=FALSE]]

cosSim <- cosineSimilarity(model_cue, model_target)


pairs <- na.omit(data.frame(as.table(cosSim))) %>%
  rename(Experimenter_Word=Var1,
         Child_Word=Var2,
         CosSim=Freq)

d_assoc_sem <- d_assoc_phon %>%
  left_join(pairs)
  


```

```{r}

word_excl <- (d_assoc_sem %>%
  filter(is.na(CosSim) | Phon_dist =="0") %>%
  distinct(Experimenter_Word))$Experimenter_Word

sem_plot <- d_assoc_sem %>%
  filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age2) %>%
  summarise(mean = mean(CosSim),
            sd = sd(CosSim),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) #%>%
  #select(-sd, -n0, -se)

sem_plot$Age2 = factor(sem_plot$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(sem_plot, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 

```

