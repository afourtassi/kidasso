---
title: "conceptNet"
date: "2/15/2018"
output: html_document
---

Libraries
```{r setup, include=FALSE}
 library(purrr)
  library(readr)
  library(ggplot2)
  library(langcog)
  library(boot)
  library(dplyr)
  library(tidyr)
  library(wordbankr)
  library(directlabels)
  library(stringr)
  library(lmtest)
  library(rwebppl)
  library(jsonlite)
  library(nlme)
  library(feather)
  library(broom)
  library(HDInterval)
  library(BBmisc)
  library(wordVectors)
  library(magrittr)
```

Data

```{r}

d <- read_delim("data/associations.txt", delim = "\t") 

dict <- read_delim("data/cmu_dict.txt", delim = ",") 

```

This function is used to recode symbols in cmu phonetic dictionary in with a unique character (easier to compute Edit distance) 
```{r}

#Read in phones and the corresponding set of characters

characters <- read_delim("data/symbolsToChar.txt", delim = "\t", col_names = FALSE) 
phones <- read_delim("data/cmu_symbols.txt", delim = "\t", col_names = FALSE)
phon_dict <- bind_cols(phones, characters)

#Converts string to its representation using the symbols
convert <- function(str, combined) {
    if (typeof(str) != "character" && class(str) != "factor") 
        stop(sprintf("Illegal data type: %s", typeof(str)))
    if (class(str) == "factor") 
        str = as.character(str)
    if (length(str) == 0)
        return(integer(0))
    splitstring = strsplit(str, split=" ")
    result_string = ""
    for (i in splitstring) {
      for (j in i) {
        filtered <- filter(combined, X1 == j)
        converted <- select(filtered, X11)
        result_string <- paste(result_string, converted)
        result_string <- gsub("[[:space:]]", "", result_string)
      }
    }
    return(result_string)
}

```
First, do some summary statistics 
```{r}
#Number of participants by age group
n_subjects <- d %>%
  group_by(Age2, Subject) %>%
  summarise(n_words=n()) %>%
  group_by(Age2) %>%
  summarise(n=n())

## We might want to collapse Olde and Younger?

#Number of words by age group
n_words <- d %>%
  group_by(Age2, Experimenter_Word) %>%
  summarise(n_subj=n()) %>%
  group_by(Age2) %>%
  summarise(n=n(),
            ave = mean(n_subj))

#Age groups

age_groups <- d %>%
  distinct(Age2, Age)

#Younger -> 3, 4, 5
#Older -> 6, 7, 8
#Adults -> 18, 19, 20, 21, 22, 24, 26, 38, 43

  
```


Reproduce the development of paradigmatic vs. syntagmatic as in Erica's previous research

```{r}
d_age <- d %>%
  group_by(Age2) %>%
  summarise(mean = mean(Para),
            sd = sd(Para),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se)
  
#d_age$Age2 = factor(d_age$Age2, levels = c("Younger", "Older", "Adult"))`

ggplot(d_age, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 

```

Entropy of answers as a function af age 

```{r}

#Definition of the entropy
#-sum(p*log_2(p))

#Normalized entropy
#-sum(p*log_2(p))/log_2(n_sample)

d_entropy <- d %>%
  group_by(Experimenter_Word, Age2, Child_Word) %>%
  summarise(n=n()) %>%
  mutate(p = n/sum(n)) %>%
  group_by(Experimenter_Word, Age2) %>%
  summarise(entropy = -sum(p*log2(p)), 
            total = n()) %>%
  mutate(entropy_norm = entropy/log2(total)) %>%# Normalized entropy
  filter(!is.na(entropy_norm)) %>%
  group_by(Age2) %>%
  summarise(mean = mean(entropy_norm), 
            sd = sd(entropy_norm),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se)
  
d_entropy$Age2 = factor(d_entropy$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(d_entropy, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) #+facet_grid( . ~ partofspeech) 


#Breaking by part of speech gives similar results within lexical category

# Do some statistical tests?

```
Include the phonetic distance in the datafarame 

```{r}
#Associations have the form: Cue -> Target

#Phonetic transcripton for Cues
Cues <- d %>%
  select(Experimenter_Word) %>%
  distinct() %>%
  mutate(Word = toupper(Experimenter_Word)) %>%
  left_join(dict) %>%
  select(-Word) %>%
  rename(cue_phon = Phonetic)

#Phonetic transcripton for Targets
Targets <- d %>%
  select(Child_Word) %>%
  distinct() %>%
  mutate(Word = toupper(Child_Word)) %>%
  left_join(dict) %>%
  select(-Word) %>%
  rename(target_phon = Phonetic)

#Include in the originial dataset
d_phon <- d %>%
  left_join(Cues) %>%
  left_join(Targets) %>%
  rowwise() %>% 
  mutate( #herer we recode the phonetic transcription to be able to use it with edit distance built in R 
    cue_code = convert(cue_phon, phon_dict), 
    target_code = ifelse(!is.na(target_phon), convert(target_phon, phon_dict), NA) #make an if statement
    ) %>%
  mutate(phon_dist =  ifelse(!is.na(target_code), adist(cue_code, target_code), NA)) 


```


Add semantic distance from Childes to the dataframe
```{r}
#Generate the model and store it in "derived"

##Uncomment the following code to re-run the Word2Vec model

#model = train_word2vec("data/corpus.txt",
#                            output="corpus.bin", threads = 4,
#                             vectors = 100, window=20, cbow=1, min_count = 10, force= TRUE)

#Read the model 
model = read.vectors("derived/corpus.bin")


cue_words <- (d %>%
  distinct(Child_Word))$Child_Word

target_words <- (d %>%
  distinct(Experimenter_Word))$Experimenter_Word

model_cue <- model[[which(rownames(model) %in% cue_words), average=FALSE]]

model_target <- model[[which(rownames(model) %in% target_words), average=FALSE]]

cosSim <- cosineSimilarity(model_cue, model_target)


pairs <- na.omit(data.frame(as.table(cosSim))) %>%
  rename(Experimenter_Word=Var1,
         Child_Word=Var2,
         CosSim=Freq)

d_phon_sem <- d_phon %>%
  left_join(pairs)

#Herer select the variables that are useful to later analyses

d_all <- d_phon_sem %>%
  select(Subject, partofspeech, Experimenter_Word, Child_Word,  Age, Age2, cue_phon, target_phon,  cue_code, target_code, phon_dist, CosSim) %>%
  dplyr::rename(cue = Experimenter_Word, 
                target = Child_Word) %>%
  mutate(Age3 = ifelse(Age2 == 'Older' | Age2 == 'Younger' , 'Young', 'Adult')) 

```

How does phonetic distance predcit associations?
```{r}

#compute average of phondistan
#Model predcit phonDist as a function of age (fixed) and Subj + cur as (ransom) will that converge?

PhonDist <- d_all %>%
  filter(!is.na(phon_dist),
         phon_dist != 0 #We also eliminate words where children just repeat the cue (e.g., apple -> apple)
         ) %>%
  group_by(Age3) %>%
  summarise(mean = mean(phon_dist),
            sd = sd(phon_dist),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) %>%
  select(-sd, -n0, -se)
  

PhonDist$Age3 = factor(PhonDist$Age3, levels = c("Young", "Adult"))
#PhonDist$Age2 = factor(PhonDist$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(PhonDist, aes(x=Age3, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1))



```

Do the same with the semantic distance
```{r}

SemDist <- d_all %>%
  filter(!is.na(CosSim),
         phon_dist != 0 #We also eliminate words where children just repeat the cue (e.g., apple -> apple)
         ) %>%
  group_by(Age3) %>%
  summarise(mean = mean(CosSim),
            sd = sd(CosSim),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) %>%
  select(-sd, -n0, -se)
  

SemDist$Age3 = factor(SemDist$Age3, levels = c("Young", "Adult"))
#SemDist$Age2 = factor(SemDist$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(SemDist, aes(x=Age3, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) #+ facet_grid( . ~ partofspeech) 

```

More analyses

```{r}
#Historams

Phon_histo <- d_all %>%
   filter(!is.na(phon_dist),
         phon_dist != 0 #We also eliminate words where children just repeat the cue (e.g., apple -> apple)
         ) %>%
  #filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age3, phon_dist) %>%
  summarise(n0 = n()) 

ggplot(Phon_histo, aes(x=phon_dist, y=n0))+
  geom_col()+
  facet_grid(. ~ Age3)

#How to quantify the rate of minimal pairs?
#E.g., for each cue, what's the probability that the target will be a minimal pair

miniDist <- d_all %>%
  filter(!is.na(phon_dist),
         phon_dist != 0 
         ) %>%
  #mutate(minimal= ifelse(phon_dist==1,1,0)) %>%
  group_by(Age3, cue) %>%
  summarise(n = n(),
            dist1 = sum(phon_dist==1)/n(),
            dist2 = sum(phon_dist==2)/n(),
            dist3 = sum(phon_dist==3)/n(), 
            dist4 = sum(phon_dist==4)/n(),
            dist5 = sum(phon_dist==5)/n(), 
            dist6 = sum(phon_dist==6)/n(),
            dist7 = sum(phon_dist==7)/n(), 
            dist8 = sum(phon_dist==8)/n(),
            dist9 = sum(phon_dist==9)/n(), 
            dist10 = sum(phon_dist==10)/n(),
            dist11 = sum(phon_dist==11)/n()
            ) %>%
  gather(phon_dist, prob, dist1:dist11) %>%
  group_by(Age3, phon_dist) %>%
  summarise(mean = mean(prob),
            sd = sd(prob),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) %>%
  select(-sd, -n0, -se)
  
miniDist$phon_dist = factor(miniDist$phon_dist, levels = c("dist1", "dist2", "dist3", "dist4", "dist5", "dist6", "dist7", "dist8", "dist9", "dist10", "dist11"))

ggplot(miniDist, aes(x=phon_dist, y=mean, col=Age3))+
  geom_line(aes(x=phon_dist, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 



   
#For each cue, what's the probability that the target is goinf to be minimal pair? 
#for each word there is a prpbability p(d=1) and we have Sum p(d=i)= 1


#ote that what makes the distributions different is the rate of minimal pairs which is disproportionately used by young children
```


Density plot for the semantic distance

```{r}

Sem_histo <- d_all %>%
   filter(!is.na(phon_dist),
         phon_dist != 0 #We also eliminate words where children just repeat the cue (e.g., apple -> apple)
         ) %>%
  #filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age3, phon_dist) %>%
  summarise(n0 = n()) 

ggplot(Phon_histo, aes(x=phon_dist, y=n0))+
  geom_col()+
  facet_grid(. ~ Age3)

yo <- ggplot(data_all,  aes(value, fill=dist))+geom_density(aes(y=..scaled..), alpha=0.2, adjust= 3) + theme(aspect.ratio = 0.7, axis.text=element_text(size=7, angle = 45)) + facet_grid(. ~ level)+
  xlab("Cosine similarity") +ylab("Count")
```


Correlation between phonetic and semantic distance
```{r}

##Here show the correlation between phonetinc and semantic distance 
phon_sem_dist <- d_assoc_all %>%
  filter(!is.na(Child_Word_phon), 
         !is.na(Child_Word),
         Phon_dist != 0,
         !is.na(CosSim)) #%>%
#  filter(!(Experimenter_Word %in% word_excl)) #%>%
  #group_by(Age2, Phon_dist) %>%
  #summarise(semSim = mean(CosSim)) 

ggplot(subset(phon_sem_dist, Phon_dist < 5), aes(x=Phon_dist, y=CosSim))+
#ggplot(phon_sem_dist, aes(x=Phon_dist, y=CosSim))+
  geom_point()+
  #geom_smooth(method = "lm")+
  geom_smooth()+
  facet_grid(. ~ Age2)


#fit <- lm(CosSim~Phon_dist, data= subset(phon_sem_dist, Age2=='Older'))
#summary(fit)



```

Now study the semantic distance 
```{r}


word_excl <- (d_assoc_all %>%
  filter(is.na(CosSim) | Phon_dist =="0") %>%
  #filter(is.na(Child_Word_phon) | Phon_dist =="0") %>%
  distinct(Experimenter_Word))$Experimenter_Word


sem_all <- d_assoc_all %>%
  filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age2) %>%
  summarise(mean = mean(CosSim),
            sd = sd(CosSim),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) %>%
  select(-sd, -n0, -se)

sem_all$Age2 = factor(sem_all$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(sem_all, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1)) 


##Break by part of speach 

sem_pos <- d_assoc_all %>%
  filter(!(Experimenter_Word %in% word_excl)) %>%
  group_by(Age2, partofspeech) %>%
  summarise(mean = mean(CosSim),
            sd = sd(CosSim),
                   n0 = n()) %>%
  mutate(se = sd / sqrt(n0),
         lower = mean - qt(1 - (0.05 / 2), n0 - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n0 - 1) * se) %>%
  select(-sd, -n0, -se)

sem_pos$Age2 = factor(sem_pos$Age2, levels = c("Younger", "Older", "Adult"))

ggplot(sem_pos, aes(x=Age2, y=mean))+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1))+
  facet_grid(. ~ partofspeech)




```

